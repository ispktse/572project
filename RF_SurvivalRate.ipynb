{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba9c05c",
   "metadata": {},
   "source": [
    "# Step 1 Data Processing\n",
    "Apply appropriate techniques to preprocess data (e.g., normalization, standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c562b91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "passenger = pd.read_csv(\"titanic_augmented.csv\")\n",
    "\n",
    "passenger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e585c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  name_length  \n",
       "0        0         A/5 21171   7.2500   NaN        S           23  \n",
       "1        0          PC 17599  71.2833   C85        C           51  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S           22  \n",
       "3        0            113803  53.1000  C123        S           44  \n",
       "4        0            373450   8.0500   NaN        S           24  \n",
       "..     ...               ...      ...   ...      ...          ...  \n",
       "886      0            211536  13.0000   NaN        S           21  \n",
       "887      0            112053  30.0000   B42        S           28  \n",
       "888      2        W./C. 6607  23.4500   NaN        S           40  \n",
       "889      0            111369  30.0000  C148        C           21  \n",
       "890      0            370376   7.7500   NaN        Q           19  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger.tail(6)\n",
    "passenger.iloc[:, 0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216309bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_group</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>ticket_group_size</th>\n",
       "      <th>fare_per_person</th>\n",
       "      <th>age_fare_ratio</th>\n",
       "      <th>cabin_deck</th>\n",
       "      <th>cabin_room_number</th>\n",
       "      <th>booking_reference</th>\n",
       "      <th>service_id</th>\n",
       "      <th>cabin_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.250</td>\n",
       "      <td>3.034483</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92490</td>\n",
       "      <td>221958</td>\n",
       "      <td>6.134152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.283</td>\n",
       "      <td>0.533084</td>\n",
       "      <td>C</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15655423</td>\n",
       "      <td>771155</td>\n",
       "      <td>4.182430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.925</td>\n",
       "      <td>3.280757</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90218500</td>\n",
       "      <td>231932</td>\n",
       "      <td>9.327285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.550</td>\n",
       "      <td>0.659134</td>\n",
       "      <td>C</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2493079</td>\n",
       "      <td>465838</td>\n",
       "      <td>8.660639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59517148</td>\n",
       "      <td>359178</td>\n",
       "      <td>0.452187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Rev</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83757278</td>\n",
       "      <td>538661</td>\n",
       "      <td>4.308875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>B</td>\n",
       "      <td>42.0</td>\n",
       "      <td>91664020</td>\n",
       "      <td>498929</td>\n",
       "      <td>2.487143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55618889</td>\n",
       "      <td>680466</td>\n",
       "      <td>6.171450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>C</td>\n",
       "      <td>148.0</td>\n",
       "      <td>94737372</td>\n",
       "      <td>673695</td>\n",
       "      <td>7.067772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.750</td>\n",
       "      <td>4.129032</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23605034</td>\n",
       "      <td>563556</td>\n",
       "      <td>1.670419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    title title_group  family_size  is_alone  ticket_group_size  \\\n",
       "0      Mr          Mr            2         0                  1   \n",
       "1     Mrs         Mrs            2         0                  1   \n",
       "2    Miss        Miss            1         1                  1   \n",
       "3     Mrs         Mrs            2         0                  2   \n",
       "4      Mr          Mr            1         1                  1   \n",
       "..    ...         ...          ...       ...                ...   \n",
       "886   Rev       Other            1         1                  1   \n",
       "887  Miss        Miss            1         1                  1   \n",
       "888  Miss        Miss            4         0                  2   \n",
       "889    Mr          Mr            1         1                  1   \n",
       "890    Mr          Mr            1         1                  1   \n",
       "\n",
       "     fare_per_person  age_fare_ratio cabin_deck  cabin_room_number  \\\n",
       "0              7.250        3.034483    Unknown                NaN   \n",
       "1             71.283        0.533084          C               85.0   \n",
       "2              7.925        3.280757    Unknown                NaN   \n",
       "3             26.550        0.659134          C              123.0   \n",
       "4              8.050        4.347826    Unknown                NaN   \n",
       "..               ...             ...        ...                ...   \n",
       "886           13.000        2.076923    Unknown                NaN   \n",
       "887           30.000        0.633333          B               42.0   \n",
       "888           11.725        0.000000    Unknown                NaN   \n",
       "889           30.000        0.866667          C              148.0   \n",
       "890            7.750        4.129032    Unknown                NaN   \n",
       "\n",
       "     booking_reference  service_id  cabin_score  \n",
       "0                92490      221958     6.134152  \n",
       "1             15655423      771155     4.182430  \n",
       "2             90218500      231932     9.327285  \n",
       "3              2493079      465838     8.660639  \n",
       "4             59517148      359178     0.452187  \n",
       "..                 ...         ...          ...  \n",
       "886           83757278      538661     4.308875  \n",
       "887           91664020      498929     2.487143  \n",
       "888           55618889      680466     6.171450  \n",
       "889           94737372      673695     7.067772  \n",
       "890           23605034      563556     1.670419  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger.iloc[:, 13:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35ca28e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>ticket_group_size</th>\n",
       "      <th>fare_per_person</th>\n",
       "      <th>age_fare_ratio</th>\n",
       "      <th>cabin_deck</th>\n",
       "      <th>cabin_room_number</th>\n",
       "      <th>booking_reference</th>\n",
       "      <th>service_id</th>\n",
       "      <th>cabin_score</th>\n",
       "      <th>name_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>1.787879</td>\n",
       "      <td>17.789001</td>\n",
       "      <td>1.572536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.49000</td>\n",
       "      <td>5.108118e+07</td>\n",
       "      <td>536369.988777</td>\n",
       "      <td>4.956762</td>\n",
       "      <td>4.067340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>1.361142</td>\n",
       "      <td>21.218127</td>\n",
       "      <td>1.661773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.39497</td>\n",
       "      <td>2.838174e+07</td>\n",
       "      <td>261551.630299</td>\n",
       "      <td>2.915177</td>\n",
       "      <td>1.168866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>9.249000e+04</td>\n",
       "      <td>102869.000000</td>\n",
       "      <td>0.046320</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.762500</td>\n",
       "      <td>0.116026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>2.831962e+07</td>\n",
       "      <td>299638.000000</td>\n",
       "      <td>2.325861</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>1.175795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.00000</td>\n",
       "      <td>5.128853e+07</td>\n",
       "      <td>535564.000000</td>\n",
       "      <td>4.954913</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.288000</td>\n",
       "      <td>2.543045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.25000</td>\n",
       "      <td>7.493131e+07</td>\n",
       "      <td>757663.000000</td>\n",
       "      <td>7.479345</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>221.779000</td>\n",
       "      <td>9.779559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>9.997588e+07</td>\n",
       "      <td>999684.000000</td>\n",
       "      <td>9.997177</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                     Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                      891   891   \n",
       "unique          NaN         NaN         NaN                      891     2   \n",
       "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
       "freq            NaN         NaN         NaN                        1   577   \n",
       "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch  Ticket        Fare  ...  \\\n",
       "count   714.000000  891.000000  891.000000     891  891.000000  ...   \n",
       "unique         NaN         NaN         NaN     681         NaN  ...   \n",
       "top            NaN         NaN         NaN  347082         NaN  ...   \n",
       "freq           NaN         NaN         NaN       7         NaN  ...   \n",
       "mean     29.699118    0.523008    0.381594     NaN   32.204208  ...   \n",
       "std      14.526497    1.102743    0.806057     NaN   49.693429  ...   \n",
       "min       0.420000    0.000000    0.000000     NaN    0.000000  ...   \n",
       "25%      20.125000    0.000000    0.000000     NaN    7.910400  ...   \n",
       "50%      28.000000    0.000000    0.000000     NaN   14.454200  ...   \n",
       "75%      38.000000    1.000000    0.000000     NaN   31.000000  ...   \n",
       "max      80.000000    8.000000    6.000000     NaN  512.329200  ...   \n",
       "\n",
       "          is_alone ticket_group_size  fare_per_person age_fare_ratio  \\\n",
       "count   891.000000        891.000000       891.000000     891.000000   \n",
       "unique         NaN               NaN              NaN            NaN   \n",
       "top            NaN               NaN              NaN            NaN   \n",
       "freq           NaN               NaN              NaN            NaN   \n",
       "mean      0.602694          1.787879        17.789001       1.572536   \n",
       "std       0.489615          1.361142        21.218127       1.661773   \n",
       "min       0.000000          1.000000         0.000000       0.000000   \n",
       "25%       0.000000          1.000000         7.762500       0.116026   \n",
       "50%       1.000000          1.000000         8.850000       1.175795   \n",
       "75%       1.000000          2.000000        24.288000       2.543045   \n",
       "max       1.000000          7.000000       221.779000       9.779559   \n",
       "\n",
       "       cabin_deck  cabin_room_number  booking_reference     service_id  \\\n",
       "count         891          200.00000       8.910000e+02     891.000000   \n",
       "unique          9                NaN                NaN            NaN   \n",
       "top       Unknown                NaN                NaN            NaN   \n",
       "freq          687                NaN                NaN            NaN   \n",
       "mean          NaN           50.49000       5.108118e+07  536369.988777   \n",
       "std           NaN           35.39497       2.838174e+07  261551.630299   \n",
       "min           NaN            2.00000       9.249000e+04  102869.000000   \n",
       "25%           NaN           22.00000       2.831962e+07  299638.000000   \n",
       "50%           NaN           43.00000       5.128853e+07  535564.000000   \n",
       "75%           NaN           77.25000       7.493131e+07  757663.000000   \n",
       "max           NaN          148.00000       9.997588e+07  999684.000000   \n",
       "\n",
       "        cabin_score  name_word_count  \n",
       "count    891.000000       891.000000  \n",
       "unique          NaN              NaN  \n",
       "top             NaN              NaN  \n",
       "freq            NaN              NaN  \n",
       "mean       4.956762         4.067340  \n",
       "std        2.915177         1.168866  \n",
       "min        0.046320         3.000000  \n",
       "25%        2.325861         3.000000  \n",
       "50%        4.954913         4.000000  \n",
       "75%        7.479345         4.000000  \n",
       "max        9.997177        14.000000  \n",
       "\n",
       "[11 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d768f4",
   "metadata": {},
   "source": [
    "# Step 2 Data Splitting and Resampling\n",
    "Split the dataset into training and test sets (25% test) and use appropriate resampling techniques (e.g., k-fold cross-validation) to ensure robust model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ed122b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PassengerId        891 non-null    int64  \n",
      " 1   Survived           891 non-null    int64  \n",
      " 2   Pclass             891 non-null    int64  \n",
      " 3   Name               891 non-null    object \n",
      " 4   Sex                891 non-null    object \n",
      " 5   Age                714 non-null    float64\n",
      " 6   SibSp              891 non-null    int64  \n",
      " 7   Parch              891 non-null    int64  \n",
      " 8   Ticket             891 non-null    object \n",
      " 9   Fare               891 non-null    float64\n",
      " 10  Cabin              204 non-null    object \n",
      " 11  Embarked           889 non-null    object \n",
      " 12  name_length        891 non-null    int64  \n",
      " 13  title              891 non-null    object \n",
      " 14  title_group        891 non-null    object \n",
      " 15  family_size        891 non-null    int64  \n",
      " 16  is_alone           891 non-null    int64  \n",
      " 17  ticket_group_size  891 non-null    int64  \n",
      " 18  fare_per_person    891 non-null    float64\n",
      " 19  age_fare_ratio     891 non-null    float64\n",
      " 20  cabin_deck         891 non-null    object \n",
      " 21  cabin_room_number  200 non-null    float64\n",
      " 22  booking_reference  891 non-null    int64  \n",
      " 23  service_id         891 non-null    int64  \n",
      " 24  cabin_score        891 non-null    float64\n",
      " 25  name_word_count    891 non-null    int64  \n",
      "dtypes: float64(6), int64(12), object(8)\n",
      "memory usage: 181.1+ KB\n"
     ]
    }
   ],
   "source": [
    "passenger.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed548aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (668, 15)\n",
      "Test set size: (223, 15)\n",
      "Survival rate in full dataset: 0.3838383838383838\n",
      "Survival rate in training set: 0.38323353293413176\n",
      "Survival rate in test set: 0.38565022421524664\n"
     ]
    }
   ],
   "source": [
    "# Drop Irrelevant, Weak, Redundant Features\n",
    "drop_cols = [\n",
    "    \"PassengerId\",    # identifier\n",
    "    \"Name\",           # title already extracted\n",
    "    \"Ticket\",         # too high-cardinality\n",
    "    \"Cabin\",           # raw cabin string; usually replaced by deck\n",
    "    \"name_length\",                  # Too many missing data and it is redundant to the decomposed ones\n",
    "    \"name_word_count\",      # Weak predictor\n",
    "    \"title\",           # Keep the title_group instead\n",
    "    \"cabin_room_number\",\n",
    "    \"booking_reference\",\n",
    "    \"service_id\"\n",
    "]\n",
    "\n",
    "cols_dropping = [col for col in drop_cols if col in passenger.columns]\n",
    "passenger_clean = passenger.drop(columns=cols_dropping)\n",
    "\n",
    "\n",
    "# Separate Predictors and Response \n",
    "target = \"Survived\"\n",
    "X = passenger_clean.drop(columns=[target])\n",
    "y = passenger_clean[target]\n",
    "\n",
    "# separate numeric and categories for future pipelining\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if 'Pclass' in num_features:\n",
    "    num_features.remove('Pclass')\n",
    "    cat_features.append('Pclass')\n",
    "\n",
    "# Pipelining\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, num_features),\n",
    "        ('cat', categorical_pipeline, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_only = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Splitting train/test \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y   # preserves class ratio\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "print(\"Survival rate in full dataset:\", y.mean())\n",
    "print(\"Survival rate in training set:\", y_train.mean())\n",
    "print(\"Survival rate in test set:\", y_test.mean())\n",
    "\n",
    "# CV re-sampling\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#StratifiedKFold(n_splits=10)\n",
    "\n",
    "\n",
    "# example placeholder for a model\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),   # from earlier step\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# useful in the future\n",
    "# scores = cross_val_score(\n",
    "#     logreg_pipeline,\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     cv=cv,\n",
    "#     scoring='accuracy'\n",
    "# )\n",
    "\n",
    "# print(\"CV Accuracy:\", scores)\n",
    "# print(\"Mean Accuracy:\", scores.mean())\n",
    "\n",
    "##Check for missing value]\n",
    "# X_check = preprocessing_only.fit_transform(X_train)\n",
    "# X_check.shape\n",
    "# np.isnan(X_check).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f23bda",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d86f8",
   "metadata": {},
   "source": [
    "### RF baseline (5-fold Stratified CV on training set)\n",
    "\n",
    "we trained a baseline RF classifier using a preprocessing + model pipline, and evaluated its expected generalization performance using 5-fold Stratified cross_validation on the training set only (seed =42).\n",
    "\n",
    "cross_val_score fits the full pipeline from scratch in each fold, meaning that imputation/encoding (and scaling, if included) are learned only from the fold's training portion, which helps prevent data leakage.\n",
    "\n",
    "The 5 fold accuracies were [0.79850746 0.84328358 0.84328358 0.82706767 0.79699248], giving a mean CV accuracy of 82% with sd 2.05%.\n",
    "\n",
    "This mean score serves as our baseline benchmark for later hyperparameter tuning and feature reduction (small yet performant), while the relatively small standard deviation indicates the model performance is fairly stable across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a6474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF CV scores: [0.79850746 0.84328358 0.84328358 0.82706767 0.79699248]\n",
      "RF Mean CV accuracy: 0.8218269554483222\n",
      "RF Std CV accuracy: 0.020536740674665727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#random forest baseline pipline\n",
    "rf_pipline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rf_scores = cross_val_score(\n",
    "    rf_pipline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "print(\"RF CV scores:\", rf_scores)\n",
    "print(\"RF Mean CV accuracy:\", rf_scores.mean())\n",
    "print(\"RF Std CV accuracy:\", rf_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431a474",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Tuning\n",
    "\n",
    "We tuned the RF classifier using RandomizedSearchCV with 5-fold stratified CV on the training set only. The best configuration achieved a mean CV accuracy of 83.53%, improving over the baseline RF mean CV accuracy (82.18%).\n",
    "\n",
    "The selected hyperparameters suggest a variance-reduction + regularization trade-off: using a large number of trees (n_estimators=1200) stabilizes the ensemble, while constraints on node splitting (min_samples_split=10, min_samples_leaf=2) reduce overfitting from overly specific splits. \n",
    "\n",
    "In addition, max_features=0.5 increases tree diversity by limiting the candidate predictors considered at each split, reducing correlation between trees and improving the effectiveness of majority voting.\n",
    "\n",
    "The best model did not required class reweighting (class_weight=None), indicating that accuracy performance was strongest without additional imbalance correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce3c29da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p (raw features): 15\n",
      "p (after preprocessing): 32\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best CV accuracy: 0.8353046796094714\n",
      "Best params: {'model__n_estimators': 1200, 'model__min_samples_split': 10, 'model__min_samples_leaf': 2, 'model__max_features': 0.5, 'model__max_depth': 30, 'model__class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#preprocessing + RF\n",
    "rf_pipeline = Pipeline(steps = [\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# check p before one-hot encoding\n",
    "p_raw = X_train.shape[1]\n",
    "print(\"p (raw features):\", p_raw)\n",
    "\n",
    "# p after after one-hot \n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "p_after = X_train_transformed.shape[1]\n",
    "print(\"p (after preprocessing):\", p_after)\n",
    "\n",
    "#Hyperparameter search space (moderate size, good chance to improve baseline)\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [300, 500, 800, 1200], # more trees => more stable, slower\n",
    "    \"model__max_depth\": [None, 5, 10, 20, 30],    # tree complexity control\n",
    "    \"model__min_samples_leaf\": [1, 2, 5, 10],     # larger leaf => less overfitting\n",
    "    \"model__min_samples_split\": [2, 5, 10],       # prevents tiny splits\n",
    "    \"model__max_features\": [\"sqrt\", 0.3, 0.5],    # RF key: randomness per split\n",
    "    \"model__class_weight\": [None, \"balanced\"]     # optional for imbalance\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,             \n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "print(\"Best CV accuracy:\", rf_search.best_score_)\n",
    "print(\"Best params:\", rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ea8e6",
   "metadata": {},
   "source": [
    "### tuned RF + get features names + importance ranking\n",
    "\n",
    "Using the tuned Random Forest, we ranked all transformed features (after one-hot encoding) by the model’s built-in impurity-based feature_importances_. The top-ranked features include title group (e.g., Mr), sex, fare-related variables, cabin-related variables, age, and passenger class, which are consistent with key survival factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4feca6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 important features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cat__title_group_Mr</td>\n",
       "      <td>0.185869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cat__Sex_male</td>\n",
       "      <td>0.111243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cat__Sex_female</td>\n",
       "      <td>0.107427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__fare_per_person</td>\n",
       "      <td>0.092487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__cabin_score</td>\n",
       "      <td>0.076581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__Fare</td>\n",
       "      <td>0.071610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__Age</td>\n",
       "      <td>0.070291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num__age_fare_ratio</td>\n",
       "      <td>0.059652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cat__Pclass_3</td>\n",
       "      <td>0.043475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__ticket_group_size</td>\n",
       "      <td>0.030258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__family_size</td>\n",
       "      <td>0.030238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cat__cabin_deck_Unknown</td>\n",
       "      <td>0.027542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__SibSp</td>\n",
       "      <td>0.013380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cat__title_group_Miss</td>\n",
       "      <td>0.008426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cat__title_group_Mrs</td>\n",
       "      <td>0.008127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "17      cat__title_group_Mr    0.185869\n",
       "11            cat__Sex_male    0.111243\n",
       "10          cat__Sex_female    0.107427\n",
       "7      num__fare_per_person    0.092487\n",
       "9          num__cabin_score    0.076581\n",
       "3                 num__Fare    0.071610\n",
       "0                  num__Age    0.070291\n",
       "8       num__age_fare_ratio    0.059652\n",
       "31            cat__Pclass_3    0.043475\n",
       "6    num__ticket_group_size    0.030258\n",
       "4          num__family_size    0.030238\n",
       "28  cat__cabin_deck_Unknown    0.027542\n",
       "1                num__SibSp    0.013380\n",
       "16    cat__title_group_Miss    0.008426\n",
       "18     cat__title_group_Mrs    0.008127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Use tuned best pipeline from Step 3\n",
    "best_rf = rf_search.best_estimator_     \n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names after preprocessing (one-hot expands)\n",
    "feature_names = best_rf.named_steps[\"preprocessing\"].get_feature_names_out()\n",
    "\n",
    "# Get RF built-in feature importance (impurity-based)\n",
    "rf_model = best_rf.named_steps[\"model\"]\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 15 important features:\")\n",
    "display(imp_df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cfb93",
   "metadata": {},
   "source": [
    "### Top-k features sweep\n",
    "\n",
    "We then performed a simple top-k sweep: starting from the most important features, we retrained the RF using only the top-k transformed features and evaluated performance using 5-fold stratified CV on the training set. Accuracy increased as k grew, and peaked at k=24 with mean CV accuracy 0.8353."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be123347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>cv_mean_acc</th>\n",
       "      <th>cv_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.806913</td>\n",
       "      <td>0.018246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.818887</td>\n",
       "      <td>0.017747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.827820</td>\n",
       "      <td>0.017352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.827797</td>\n",
       "      <td>0.019974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.829312</td>\n",
       "      <td>0.017010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>0.829335</td>\n",
       "      <td>0.016091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>0.835327</td>\n",
       "      <td>0.016453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>0.833812</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>0.832297</td>\n",
       "      <td>0.017822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  cv_mean_acc    cv_std\n",
       "0   5     0.806913  0.018246\n",
       "1   8     0.818887  0.017747\n",
       "2  10     0.827820  0.017352\n",
       "3  12     0.827797  0.019974\n",
       "4  16     0.829312  0.017010\n",
       "5  20     0.829335  0.016091\n",
       "6  24     0.835327  0.016453\n",
       "7  28     0.833812  0.016234\n",
       "8  32     0.832297  0.017822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# transform training set once (after preprocessing)\n",
    "Xt_train = best_rf.named_steps[\"preprocessing\"].fit_transform(X_train, y_train)\n",
    "\n",
    "# Create top indices based on sorted importance\n",
    "top_idx = np.argsort(importances)[::-1]   \n",
    "\n",
    "# 3) Use the tuned RF params to create a model (same as best model)\n",
    "best_params = rf_search.best_params_\n",
    "rf_tuned = RandomForestClassifier(\n",
    "    n_estimators=best_params[\"model__n_estimators\"],\n",
    "    max_depth=best_params[\"model__max_depth\"],\n",
    "    min_samples_split=best_params[\"model__min_samples_split\"],\n",
    "    min_samples_leaf=best_params[\"model__min_samples_leaf\"],\n",
    "    max_features=best_params[\"model__max_features\"],\n",
    "    class_weight=best_params[\"model__class_weight\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4) Try different k \n",
    "k_list = [5, 8, 10, 12, 16, 20, 24, 28, 32]\n",
    "\n",
    "rows = []\n",
    "for k in k_list:\n",
    "    cols = top_idx[:k]\n",
    "    Xt_k = Xt_train[:, cols]\n",
    "\n",
    "    scores = cross_val_score(rf_tuned, Xt_k, y_train, cv=cv, scoring=\"accuracy\")\n",
    "    rows.append({\n",
    "        \"k\": k,\n",
    "        \"cv_mean_acc\": scores.mean(),\n",
    "        \"cv_std\": scores.std()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38b336",
   "metadata": {},
   "source": [
    "### pick smallest K within tolerance\n",
    "\n",
    "With a tolerance of 0.005 (0.5%) from the best CV score, we selected k=24 as the smallest feature set meeting this threshold. Since the transformed feature space has 32 features, this reduces the feature set by 25% while keeping CV performance nearly unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8c6def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV mean accuracy: 0.8353271237795983\n",
      "Threshold (best - tolerance): 0.8303271237795983\n",
      "Chosen smallest k: 24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tolerance = 0.005  # allow up to 0.5% drop from the best CV mean accuracy\n",
    "\n",
    "best_mean = results_df[\"cv_mean_acc\"].max()\n",
    "threshold = best_mean - tolerance\n",
    "\n",
    "# choose the smallest k whose mean accuracy >= threshold\n",
    "best_k = int(\n",
    "    results_df[results_df[\"cv_mean_acc\"] >= threshold]\n",
    "    .sort_values(\"k\")\n",
    "    .iloc[0][\"k\"]\n",
    ")\n",
    "\n",
    "print(\"Best CV mean accuracy:\", best_mean)\n",
    "print(\"Threshold (best - tolerance):\", threshold)\n",
    "print(\"Chosen smallest k:\", best_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0b36b",
   "metadata": {},
   "source": [
    "### Final evaluation on the test set\n",
    "\n",
    "After selecting k=24, we refit preprocessing on the full training set, trained the tuned RF on the top-k features, and evaluated once on the held-out test set. The top-k model achieved test accuracy = 0.8117 with confusion matrix \\[122,15,27,59]. This indicates the model makes relatively few false positives (15), while some survivors are predicted as non-survivors (27), suggesting recall for the Survived class is lower than precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b47d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (top-k): 0.8116591928251121\n",
      "Confusion matrix:\n",
      " [[122  15]\n",
      " [ 27  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Transform train/test using preprocessing (fit on train only)\n",
    "Xt_train = best_rf.named_steps[\"preprocessing\"].fit_transform(X_train, y_train)\n",
    "Xt_test  = best_rf.named_steps[\"preprocessing\"].transform(X_test)\n",
    "\n",
    "# Select top-k columns\n",
    "cols = top_idx[:best_k]\n",
    "Xt_train_k = Xt_train[:, cols]\n",
    "Xt_test_k  = Xt_test[:, cols]\n",
    "\n",
    "# Fit tuned RF on reduced features\n",
    "rf_tuned.fit(Xt_train_k, y_train)\n",
    "\n",
    "# Predict on test\n",
    "y_pred = rf_tuned.predict(Xt_test_k)\n",
    "\n",
    "print(\"Test accuracy (top-k):\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c27b9",
   "metadata": {},
   "source": [
    "## Random Forest (RF) Summary\n",
    "\n",
    "### Setup\n",
    "- Train/test split: 75/25 with `stratify=y`, `random_state=42`\n",
    "- 5-fold Stratified CV (`shuffle=True`, `random_state=42`)\n",
    "- Preprocessing: median imputation for numeric, most-frequent imputation + one-hot encoding for categorical features\n",
    "\n",
    "### Step 2 — RF Baseline (CV on training set)\n",
    "- CV accuracy scores: [0.7985, 0.8433, 0.8433, 0.8271, 0.7970]\n",
    "- Mean CV accuracy = **0.8218**, Std = **0.0205**\n",
    "\n",
    "### Step 3 — RF Hyperparameter Tuning (RandomizedSearchCV)\n",
    "- 30 random candidates × 5 folds = 150 total fits (train-only CV)\n",
    "- Best mean CV accuracy = **0.8353**\n",
    "- Best params:\n",
    "  - `n_estimators=1200`, `max_depth=30`, `min_samples_split=10`, `min_samples_leaf=2`,\n",
    "  - `max_features=0.5`, `class_weight=None`\n",
    "\n",
    "### Step 4 — Small yet performant (Top-k feature reduction)\n",
    "- Feature count:\n",
    "  - p (raw) = **15**\n",
    "  - p (after preprocessing) = **32**\n",
    "- Used RF built-in `feature_importances_` to rank transformed features (e.g., title group, sex, fare, cabin, age, Pclass)\n",
    "- Top-k sweep (5-fold CV):\n",
    "  - Best mean CV accuracy = **0.8353**\n",
    "  - Tolerance = **0.005** (0.5 percentage points)\n",
    "  - Threshold = **0.8303**\n",
    "  - Chosen smallest k within tolerance = **24**\n",
    "- This reduces transformed features from **32 → 24** (**25% reduction**) while keeping CV performance near the best.\n",
    "\n",
    "### Final Test Evaluation (Top-k model)\n",
    "- Test accuracy (k=24) = **0.8117**\n",
    "- Confusion matrix:\n",
    "  - [[122, 15],\n",
    "     [27, 59]]\n",
    "  - The model makes relatively few false positives (15), while some survivors are predicted as non-survivors (27).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86731239",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09ad48",
   "metadata": {},
   "source": [
    "We trained a Random Forest classifier to predict passenger survival. The dataset was split into training and test sets using a 75/25 split with stratification on the target label (random_state=42). All model selection steps were performed on the training set only using 5-fold Stratified cross-validation (shuffle=True, seed=42). Preprocessing was implemented using a pipeline: numeric features were median-imputed, categorical features were imputed with the most frequent category and one-hot encoded. We first established a baseline RF using CV, then tuned hyperparameters with RandomizedSearchCV (30 random candidates evaluated by 5-fold CV, totalling 150 fits). Finally, to support the project goal of building a “small yet performant” model, we ranked transformed features using the tuned RF’s built-in impurity-based feature importance (feature_importances_) and performed a top-k feature sweep. We selected the smallest k whose mean CV accuracy was within a tolerance of 0.005 (0.5 percentage points) of the best observed CV score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc17ed5",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d887cb",
   "metadata": {},
   "source": [
    "The baseline Random Forest achieved mean CV accuracy 0.8218 (std 0.0205) on the training set. After tuning, the best model achieved mean CV accuracy 0.8353 with parameters: n_estimators=1200, max_depth=30, min_samples_split=10, min_samples_leaf=2, max_features=0.5, class_weight=None. After preprocessing, the model operated on 32 transformed features (from 15 raw predictors). Using the importance ranking and top-k sweep, we found that k=24 features achieved the best observed mean CV accuracy (0.8353) and was also the smallest k within the tolerance threshold (0.8303), reducing the transformed feature set from 32 to 24 (a 25% reduction) while maintaining near-peak CV performance. The final top-k model achieved test accuracy = 0.8117 with confusion matrix \\[122,15,27,59], indicating relatively few false positives but a moderate number of false negatives for the Survived class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89973170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
